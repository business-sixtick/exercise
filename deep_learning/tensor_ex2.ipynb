{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 (epoch):\n",
      " 99\n",
      "편향 (Biases):\n",
      " [ 0.05381237 -0.07790495  0.09024163  0.09180333 -0.05116507  0.05496046\n",
      " -0.05204893  0.02591392 -0.04011229 -0.05031352 -0.04986227 -0.03133543\n",
      " -0.05138624 -0.04822321 -0.08128776 -0.05119121 -0.07727905 -0.04902872\n",
      "  0.06245451  0.05364668  0.14040914 -0.02523985  0.03503371 -0.05004516\n",
      "  0.26443678  0.16940989 -0.06295951  0.05573026  0.00579275 -0.07102515\n",
      " -0.03561545  0.12492216]\n",
      "가중치 (Weights):\n",
      " [[ 0.07732277 -0.41070315  0.11250913 -0.25933883 -0.25474745 -0.21342966\n",
      "   0.09974068 -0.05379367  0.03446195 -0.16835389 -0.11199316 -0.13212815\n",
      "  -0.2906011   0.12629656 -0.09632234  0.12341292  0.22401662  0.29193786\n",
      "   0.00907331 -0.09153386 -0.18273936  0.23914135  0.27763388  0.3337366\n",
      "  -0.14279005  0.7541726   0.08698562 -0.0308938  -0.33252525 -0.12985674\n",
      "  -0.24993095 -0.28065628]\n",
      " [ 0.30108038 -0.08489244  0.23161402 -0.27286777  0.21955162  0.2753279\n",
      "  -0.31992224  0.27269578  0.05674119  0.23210034 -0.30508906  0.27571875\n",
      "   0.13678585 -0.34704888 -0.405951    0.27950728  0.21231799 -0.31306526\n",
      "   0.1439098  -0.03362135  0.41944358 -0.26850954 -0.06889706  0.19237372\n",
      "   0.0721247   0.22573517 -0.22775953  0.0250403   0.1746243   0.15509973\n",
      "   0.30625898  0.2419393 ]\n",
      " [ 0.33518714 -0.2187655  -0.00827729 -0.01761109  0.15163761  0.00766996\n",
      "   0.20505244 -0.21004954 -0.3350693   0.3264787   0.21840988  0.18314774\n",
      "   0.04025357  0.29497954 -0.18368281 -0.17373024 -0.39864883 -0.3538928\n",
      "  -0.24585912 -0.11425383  0.14224364 -0.25298545  0.25403455 -0.08718915\n",
      "  -0.00358118  0.13678394 -0.35525638 -0.10985439 -0.13474642 -0.33052358\n",
      "   0.09287237 -0.12993567]\n",
      " [ 0.03418995 -0.06400334 -0.09808799  0.17237334  0.2681073  -0.16667528\n",
      "  -0.3503012   0.27251577 -0.02521968  0.16238101  0.20622459  0.22496979\n",
      "  -0.26084653 -0.26760405  0.21489441 -0.2653127  -0.17859368 -0.22690159\n",
      "  -0.37032008 -0.15857227 -0.36850682 -0.28862262 -0.23218496 -0.23119886\n",
      "  -0.03278884  0.59222835  0.27413955  0.22866164 -0.03607054  0.04763126\n",
      "   0.07108323 -0.10770663]\n",
      " [-0.2472843  -0.14252797 -0.2980877   0.17441726 -0.08298469 -0.15560389\n",
      "  -0.083586   -0.15339708  0.14159387 -0.07784241 -0.19488361  0.2394949\n",
      "   0.41634026 -0.04474078 -0.00477745  0.27754825  0.33985248 -0.08701488\n",
      "  -0.19123621 -0.05791382 -0.32358995  0.17772217 -0.2526592   0.06709568\n",
      "  -0.39184162  0.7820103  -0.21715756 -0.2974223  -0.24591783 -0.3160774\n",
      "   0.03927773 -0.55402064]\n",
      " [-0.33291352  0.09215681  0.17685835 -0.14700897  0.15385118 -0.24588269\n",
      "  -0.21852627 -0.27848476 -0.22469722  0.12646931  0.2266771   0.06595369\n",
      "   0.09351253 -0.25053573 -0.13356557 -0.1055344   0.32750097  0.21602397\n",
      "  -0.10334395 -0.36827266 -0.09002255  0.14691445 -0.21657553  0.26987493\n",
      "  -0.03095959  0.7411989  -0.2153634  -0.01831979  0.03903011 -0.26418647\n",
      "   0.02118611 -0.18306041]\n",
      " [-0.2505889  -0.00312308  0.48374748 -0.41704637  0.4869796  -0.6208825\n",
      "   0.10956299  0.19464852 -0.00614324  0.5404241   0.5966853   0.05634328\n",
      "  -0.06875986  0.46809083 -0.13562763  0.49603575  0.33220947  0.41228873\n",
      "  -0.40864617 -0.39378607 -0.3243447  -0.27743956 -0.3463498   0.14308198\n",
      "  -0.21734062  0.00256928 -0.00820142 -0.32581365 -0.30230135  0.1720291\n",
      "   0.17868622  0.41008592]\n",
      " [ 0.17344138 -0.01409737 -0.16967903 -0.33876     0.09449857 -0.24696863\n",
      "   0.23970674  0.14415143  0.16593052 -0.21060732 -0.17926471  0.12668258\n",
      "  -0.17416708 -0.18114878  0.11200681  0.17605947  0.11648986  0.07588393\n",
      "   0.06163317  0.07093667 -0.31393328  0.21553814 -0.21898201 -0.3187807\n",
      "  -0.23293427  0.9819134  -0.17743032  0.09594137 -0.43213376 -0.09114265\n",
      "   0.08077328  0.0194311 ]\n",
      " [-0.21820468 -0.07633423 -0.14406537 -0.1781725  -0.16636497 -0.40631345\n",
      "  -0.10630514 -0.08217034  0.3819612   0.1668146  -0.14035916 -0.26951623\n",
      "   0.28709543  0.16778909  0.10696108  0.02574589  0.27028742 -0.11931609\n",
      "  -0.10455466  0.22362405 -0.6429019  -0.3604204   0.21260421 -0.0540598\n",
      "  -0.70315725 -0.7841482   0.33757907  0.13284732  0.08963349  0.14992218\n",
      "   0.05772185 -0.19374959]\n",
      " [-0.48897052 -0.26439333  0.1701642  -0.18343434  0.00812612 -0.27136734\n",
      "  -0.11659007 -0.056642    0.20267208  0.30985203  0.10283655  0.11774553\n",
      "  -0.08658511 -0.25205812 -0.32797715  0.07272662  0.02062105  0.21269186\n",
      "   0.13882075  0.17569473 -0.53843033  0.12570135  0.02161718  0.14707525\n",
      "  -0.69044346 -0.3338318   0.22761397  0.03168176 -0.07528252  0.02824556\n",
      "  -0.23006757  0.00519801]\n",
      " [-0.33757505 -0.03148799 -0.2816047  -0.18304318  0.3694357  -0.42648375\n",
      "   0.01651288  0.1297633   0.52799547 -0.03134806  0.15999316 -0.01144561\n",
      "  -0.11643534  0.2674674  -0.32840294  0.4103075  -0.26135337  0.1043104\n",
      "  -0.6398596   0.0695397  -0.3682165  -0.15822858 -0.06889886  0.52076\n",
      "  -0.5868254   0.7362808  -0.32642248  0.08908976 -0.5997973   0.08729551\n",
      "  -0.04412308 -0.08044656]\n",
      " [ 0.4472416  -0.35025814  0.3590713   0.55854946 -0.5067533   0.11437254\n",
      "  -0.44414523  0.14676942  0.09269785 -0.4734688   0.09129441 -0.28955948\n",
      "  -0.1875448  -0.21141255 -0.02928404 -0.3697404   0.15512604  0.0636137\n",
      "   0.6370367   0.07744761  0.36973515  0.2489148   0.46532336 -0.10237417\n",
      "   0.6533615   0.940743   -0.32030892  0.37256703  0.57209015  0.08865035\n",
      "   0.01034805  0.81020504]\n",
      " [-0.13184561 -0.0188263   0.24046381 -0.3858995   0.22587405  0.24540043\n",
      "  -0.00995346  0.07726099 -0.0973252   0.201847    0.07690297 -0.15065417\n",
      "   0.32246324  0.0670001   0.01316565  0.24603064  0.0813949  -0.1923692\n",
      "  -0.26921383  0.13877518 -0.18355986 -0.05614677  0.02760094  0.2251327\n",
      "  -0.27729613  0.5257758   0.21714461 -0.25204453  0.29123345  0.13252456\n",
      "  -0.36769518  0.3450641 ]\n",
      " [ 0.27981433  0.29457775 -0.45548636  0.18482386  0.23020782 -0.28323317\n",
      "  -0.04630995  0.30653405  0.32121143  0.35042712  0.36253706 -0.02212621\n",
      "   0.01142732 -0.34170014  0.21030904  0.15188026 -0.26065776  0.31326538\n",
      "  -0.03612625 -0.1904303  -0.26100567 -0.35467732 -0.15786728 -0.23836674\n",
      "  -0.32266706 -0.12426366 -0.01904697  0.27060753 -0.07522102 -0.04885484\n",
      "  -0.191777   -0.00189423]\n",
      " [ 0.28461528 -0.0494808   0.30870453  0.3209927  -0.3052476  -0.04213558\n",
      "   0.12158482  0.20114776 -0.02671168 -0.21641289 -0.43462425 -0.03645265\n",
      "  -0.24915595  0.11296795 -0.25941178 -0.35155106 -0.09553982  0.18332954\n",
      "   0.16284269  0.1862216   0.47479033 -0.10675532  0.5505684  -0.43420628\n",
      "   0.9357344   0.36379573 -0.07017447 -0.10763398  0.14749855 -0.2785421\n",
      "  -0.04039128  0.36050034]\n",
      " [ 0.21641117 -0.16438551 -0.05835475  0.03789412  0.21185483  0.17581685\n",
      "   0.187048   -0.0813102   0.04006918  0.03920498  0.06539419 -0.3536143\n",
      "   0.2842963   0.17716305 -0.25327283  0.21509807 -0.32896683  0.14898267\n",
      "   0.14402205  0.27239406  0.02710067 -0.01425818 -0.03486397  0.1267078\n",
      "   0.04936389 -0.1422814  -0.34253767  0.13416247  0.16216543 -0.28133848\n",
      "  -0.18980256 -0.01604239]]\n",
      "정확도 (Biases):\n",
      " 0.848936140537262\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8489\n",
      "Loss: 0.3801777958869934, Accuracy: 0.848936140537262\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Sequential = tf.keras.Sequential # 모델\n",
    "Dense = tf.keras.layers.Dense # 뉴런\n",
    "import os\n",
    "\n",
    "def clear_screen():\n",
    "    # 운영체제에 따라 화면을 지우는 명령어 선택\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "from IPython.display import clear_output\n",
    "\n",
    "path = r'https://github.com/taehojo/deeplearning/raw/master/data/ThoraricSurgery3.csv'\n",
    "df = pd.read_csv(path, header=None)\n",
    "model = Sequential()\n",
    "# df.info() # 470 * 17 . y = [16]\n",
    "# input 15 input_shape=(2,)\n",
    "model.add(Dense(16 * 2, input_shape=(16,), activation='relu'))  # 1개의 뉴런을 가진 출력층, input_dim 입력층 구멍 개수 sigmoid 활성화 함수\n",
    "# model.add(Dense(15 * 2, input_dim=15, activation='relu'))  # 1개의 뉴런을 가진 출력층, input_dim 입력층 구멍 개수 sigmoid 활성화 함수\n",
    "# model.add(Dense(32, activation='relu')) #softplus relu\n",
    "model.add(Dense(1, activation='sigmoid')) # softmax tanh\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "x_train = df.iloc[:, 0:16]\n",
    "y_train = df[16]\n",
    "# x_train\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    history = model.fit(x_train, y_train, epochs=1, verbose=1)\n",
    "    # 가중치와 편향 출력\n",
    "    weights, biases = model.layers[0].get_weights()\n",
    "    clear_output(wait=True) # clear_screen()\n",
    "    print(\"에포크 (epoch):\\n\", epoch)\n",
    "    print(\"편향 (Biases):\\n\", biases)\n",
    "    print(\"가중치 (Weights):\\n\", weights)\n",
    "    \n",
    "    accuracy = history.history['accuracy'][0]\n",
    "    print(\"정확도 (Biases):\\n\", accuracy)\n",
    "    if accuracy == 1.0 and epochs > 10 :\n",
    "        print(f\"정확도가 100%에 도달한 에포크: {epoch + 1}\")\n",
    "        break\n",
    "# model.fit(x_train, y_train, epochs=5, verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2   3   4   5   6   7   8   9   10  11  12  13  14  15  16\n",
       "0   1  2.88  2.16   1   0   0   0   1   1   3   0   0   0   1   0  60   0\n",
       "1   2  3.40  1.88   0   0   0   0   0   0   1   0   0   0   1   0  51   0\n",
       "2   2  2.76  2.08   1   0   0   0   1   0   0   0   0   0   1   0  59   0\n",
       "3   2  3.68  3.04   0   0   0   0   0   0   0   0   0   0   0   0  54   0\n",
       "4   2  2.44  0.96   2   0   1   0   1   1   0   0   0   0   1   0  73   1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
