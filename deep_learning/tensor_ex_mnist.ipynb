{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m layers \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msl\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Sequential = tf.keras.Sequential # 모델\n",
    "Dense = tf.keras.layers.Dense # 뉴런\n",
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "matplotlib.rc('font', family='gulim') # NanumGothic  gulim NanumSquareRoundR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1809 - accuracy: 0.9427 - val_loss: 0.0497 - val_accuracy: 0.9839\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0668 - accuracy: 0.9801 - val_loss: 0.0464 - val_accuracy: 0.9852\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0498 - accuracy: 0.9845 - val_loss: 0.0440 - val_accuracy: 0.9855\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0377 - val_accuracy: 0.9890\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.0349 - val_accuracy: 0.9902\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0318 - accuracy: 0.9898 - val_loss: 0.0285 - val_accuracy: 0.9922\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.0331 - val_accuracy: 0.9902\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0297 - val_accuracy: 0.9913\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0289 - val_accuracy: 0.9922\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0324 - val_accuracy: 0.9907\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0314 - val_accuracy: 0.9918\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0308 - val_accuracy: 0.9911\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0350 - val_accuracy: 0.9903\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0415 - val_accuracy: 0.9912\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0392 - val_accuracy: 0.9921\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0314 - val_accuracy: 0.9917\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0425 - val_accuracy: 0.9901\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0518 - val_accuracy: 0.9909\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0375 - val_accuracy: 0.9917\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0349 - val_accuracy: 0.9920\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0372 - val_accuracy: 0.9924\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0385 - val_accuracy: 0.9928\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0437 - val_accuracy: 0.9917\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0329 - val_accuracy: 0.9931\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0410 - val_accuracy: 0.9921\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0421 - val_accuracy: 0.9913\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0447 - val_accuracy: 0.9919\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0491 - val_accuracy: 0.9910\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0414 - val_accuracy: 0.9924\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0462 - val_accuracy: 0.9928\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0567 - val_accuracy: 0.9922\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.0569 - val_accuracy: 0.9909\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0400 - val_accuracy: 0.9931\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0496 - val_accuracy: 0.9919\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0422 - val_accuracy: 0.9920\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0387 - val_accuracy: 0.9925\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0389 - val_accuracy: 0.9927\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0440 - val_accuracy: 0.9917\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0424 - val_accuracy: 0.9925\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0434 - val_accuracy: 0.9918\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0466 - val_accuracy: 0.9919\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0506 - val_accuracy: 0.9911\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0542 - val_accuracy: 0.9930\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0515 - val_accuracy: 0.9918\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0509 - val_accuracy: 0.9912\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0614 - val_accuracy: 0.9915\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0675 - val_accuracy: 0.9910\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0651 - val_accuracy: 0.9910\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0604 - val_accuracy: 0.9916\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0733 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "Precision = tf.keras.metrics.Precision\n",
    "Recall = tf.keras.metrics.Recall\n",
    "AUC = tf.keras.metrics.AUC\n",
    "ModelCheckpoint = tf.keras.callbacks.ModelCheckpoint\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping\n",
    "# MNIST 데이터셋 로드\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 데이터 정규화 (0~255 범위의 픽셀 값을 0~1 사이로 변환)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(type(x_train))\n",
    "# 간단한 CNN 모델 정의\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(28, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # layers.Dropout(0.5),\n",
    "    layers.Conv2D(28, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(392, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(196, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_78 (Conv2D)          (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 13, 13, 28)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 11, 11, 28)        7084      \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 5, 5, 28)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 700)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 392)               274792    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 392)               0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 196)               77028     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 196)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 10)                1970      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361,154\n",
      "Trainable params: 361,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9912\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      1.00      1.00      1135\n",
      "           2       1.00      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      1.00      0.99      1028\n",
      "           8       1.00      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 976    0    0    0    0    0    3    1    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   2    1 1020    2    0    0    0    7    0    0]\n",
      " [   0    0    0 1004    0    2    0    2    2    0]\n",
      " [   0    0    0    0  969    0    4    0    0    9]\n",
      " [   3    0    1    5    0  880    3    0    0    0]\n",
      " [   3    4    0    0    1    0  950    0    0    0]\n",
      " [   0    2    0    0    0    0    0 1024    1    1]\n",
      " [   3    1    1    1    0    0    1    2  961    4]\n",
      " [   0    0    0    1    5    5    0    3    1  994]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# 분류 문제인 경우: 예측 클래스 라벨 얻기\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 실제 레이블과 예측된 라벨 비교\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 분류 보고서 출력\n",
    "report = classification_report(y_test, y_pred_classes)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.1535910815000534],\n",
       " 'accuracy': [0.9523500204086304],\n",
       " 'val_loss': [0.05092945322394371],\n",
       " 'val_accuracy': [0.984000027179718]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.metrics.Precision at 0x1d28829e4c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "Precision = tf.keras.metrics.Precision\n",
    "Recall = tf.keras.metrics.Recall\n",
    "AUC = tf.keras.metrics.AUC\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), AUC()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 설정\n",
    "early_stopping_cb = EarlyStopping(\n",
    "    monitor='val_loss',            # 모니터링할 지표\n",
    "    patience=3,                    # 성능 개선이 없더라도 기다릴 에폭 수\n",
    "    restore_best_weights=True,     # 학습 중 최상의 가중치 복원\n",
    "    verbose=1                      # 로그 출력 여부\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping_cb]  # 콜백 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint 콜백 설정\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    'model_checkpoint.h5',        # 모델을 저장할 파일 경로\n",
    "    save_best_only=True,            # 가장 좋은 성능의 모델만 저장\n",
    "    monitor='val_loss',            # 모니터링할 지표\n",
    "    mode='min',                    # 'min' 또는 'max' (val_loss의 경우 'min')\n",
    "    verbose=1                      # 로그 출력 여부\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpoint_cb]      # 콜백 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28* 28\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
